{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Mô hình ngôn ngữ và ứng dụng cho kiểm lỗi chính tả\n",
    "\n",
    "#### Mục tiêu: xây dựng chương trình kiểm lỗi cú pháp tiếng Anh đơn giản \n",
    "\n",
    "Bài 1:  \n",
    "\n",
    "a)\tXây dựng mô hình ngôn ngữ dựa trên n-gram sử dụng phương pháp smoothing là Laplace, cho các mô hình:\n",
    "-\t1-gram\n",
    "-\t2-gram\n",
    "-\t3-gram\n",
    "\n",
    "b)\tTính xác suất của một câu và tính Perplexity của một câu dựa theo 1-gram, 2-gram, 3-gram\n",
    "\n",
    "c)\tPhân tích kết quả\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đọc file input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "[\"Here are two reasons companies fail: they only do more of the same, or they only do what's new\", 'To me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation', 'Both are necessary, but it can be too much of a good thing', 'Consider Facit', \"I'm actually old enough to remember them\"]\n"
     ]
    }
   ],
   "source": [
    "# đọc file\n",
    "filename='tedtalk.txt'\n",
    "with open(filename, 'r', encoding='utf-8')  as file:\n",
    "    lines=file.readlines()\n",
    "\n",
    "max_lines = 10000 \n",
    "lines=lines[:max_lines]\n",
    "# drop \\n:\n",
    "lines=[line.strip() for line in lines]\n",
    "print(len(lines))\n",
    "print(lines[:5])     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cài đặt thư viện xử lý ngôn ngữ nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\gia bao\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\gia bao\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\gia bao\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\gia bao\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gia bao\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\gia bao\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Gia\n",
      "[nltk_data]     Bao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thực hiện tokenize tập input\n",
    "Thêm '\\<s\\>' vào trước mỗi câu, thêm '\\</s\\>' vào sau mỗi câu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_tokens_count= 206296\n",
      "10000\n",
      "[['<s>', 'Here', 'are', 'two', 'reasons', 'companies', 'fail', ':', 'they', 'only', 'do', 'more', 'of', 'the', 'same', ',', 'or', 'they', 'only', 'do', 'what', \"'s\", 'new', '</s>'], ['<s>', 'To', 'me', 'the', 'real', ',', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', ':', 'exploration', 'and', 'exploitation', '</s>'], ['<s>', 'Both', 'are', 'necessary', ',', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing', '</s>'], ['<s>', 'Consider', 'Facit', '</s>'], ['<s>', 'I', \"'m\", 'actually', 'old', 'enough', 'to', 'remember', 'them', '</s>']]\n"
     ]
    }
   ],
   "source": [
    "# tokenize sentences \n",
    "import nltk\n",
    "sentences=[]\n",
    "all_tokens_count=0\n",
    "\n",
    "for line in lines:\n",
    "    tokens=nltk.word_tokenize(line)\n",
    "    tokens.insert(0,'<s>')\n",
    "    tokens.append('</s>')\n",
    "    all_tokens_count+=len(tokens)\n",
    "    sentences.append(tokens)\n",
    "    \n",
    "print('all_tokens_count=',all_tokens_count)\n",
    "print(len(sentences))\n",
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 11320), ('<s>', 10000), ('</s>', 10000), ('the', 7556), ('to', 4978), ('of', 4444), ('and', 4151), ('a', 3930), ('that', 3454), ('I', 3068)]\n",
      "V= 13741\n",
      "n= 186296\n",
      "7556\n",
      "289\n"
     ]
    }
   ],
   "source": [
    "# counting 1-gram \n",
    "from collections import Counter\n",
    "counter_unigram=Counter()\n",
    "\n",
    "#ENTER YOU CODE HERE\n",
    "#-> Dùng counter_unigram để đếm token 1-gram cho tập sentences\n",
    "for sentence in sentences:\n",
    "    counter_unigram.update(sentence)\n",
    "\n",
    "print(counter_unigram.most_common(10))\n",
    "\n",
    "V=len(counter_unigram)\n",
    "\n",
    "print('V=',V)\n",
    "\n",
    "n=0\n",
    "for gram in counter_unigram:\n",
    "    n+=counter_unigram[gram]\n",
    "n=n-counter_unigram['<s>']-counter_unigram['</s>']\n",
    "\n",
    "\n",
    "print('n=',n)\n",
    "print(counter_unigram['the'])\n",
    "print(counter_unigram['he'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196296\n",
      "('<s>', 'Here')\n",
      "('Here', 'are')\n",
      "('are', 'two')\n",
      "V= 81850\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "bi_grams=[]\n",
    "\n",
    "\n",
    "#ENTER YOU CODE HERE\n",
    "#-> Dùng ngrams để đếm token 2-gram cho tập sentences\n",
    "for sentence in sentences:\n",
    "    bi_grams.extend(ngrams(sentence,2))\n",
    "#END YOUR CODE\n",
    "    \n",
    "print(len(bi_grams))\n",
    "\n",
    "for i in range(3):\n",
    "    print(bi_grams[i])\n",
    "\n",
    "counter_bigram = Counter(bi_grams)\n",
    "\n",
    "print('V=',len(counter_bigram))\n",
    "print(counter_bigram[('here','are')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186296\n",
      "('<s>', 'Here', 'are')\n",
      "('Here', 'are', 'two')\n",
      "('are', 'two', 'reasons')\n",
      "V= 143772\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "tri_grams=[]\n",
    "\n",
    "#ENTER YOU CODE HERE\n",
    "#-> Dùng ngrams để đếm token 3-gram cho tập sentences\n",
    "for sentence in sentences:\n",
    "    tri_grams.extend(ngrams(sentence,3))\n",
    "#END YOUR CODE\n",
    "    \n",
    "print(len(tri_grams))\n",
    "\n",
    "for i in range(3):\n",
    "    print(tri_grams[i])\n",
    "\n",
    "counter_trigram = Counter(tri_grams)\n",
    "print('V=',len(counter_trigram))\n",
    "print(counter_trigram[('here','are','two')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viết hàm tính xác suất cho từng loại: 1-gram, 2-gram, 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tính prob theo từng loại: 1-gram, 2-gram, 3-gram\n",
    "def uni_prob(word):\n",
    "    #ENTER YOU CODE HERE\n",
    "    #-> tính xác suất 1-gram\n",
    "    return (counter_unigram[word]+1)/(n+V)\n",
    "    #END YOUR CODE\n",
    "\n",
    "def bi_prob(word1,word2):\n",
    "    #ENTER YOU CODE HERE\n",
    "    #-> tính xác suất 2-gram\n",
    "    return (counter_bigram[(word1,word2)]+1)/(counter_unigram[word1]+V)\n",
    "    #END YOUR CODE\n",
    "    \n",
    "def tri_prob(word1,word2,word3):\n",
    "    #ENTER YOU CODE HERE\n",
    "    #-> tính xác suất 3-gram\n",
    "    return (counter_trigram[(word1,word2,word3)]+1)/(counter_bigram[(word1,word2)]+V)\n",
    "    #END YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viết hàm tính xác xuất cho một câu, normalize theo 1 từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tính xác suất của một câu, normalize theo 1 từ \n",
    "def probLM(sent,n):\n",
    "    if n>3 or n<1: # không xét trường hợp này \n",
    "        return 0\n",
    "    tokens=nltk.word_tokenize(sent.lower())\n",
    "    tokens += ['<s>']+tokens\n",
    "    prob=1\n",
    "    for i in range(1,len(tokens)):\n",
    "        if n==1:\n",
    "            prob*=uni_prob(tokens[i])\n",
    "        elif n==2:\n",
    "            prob*=bi_prob(tokens[i-1],tokens[i])\n",
    "        elif n==3:\n",
    "            if i>=2:\n",
    "                prob*=tri_prob(tokens[i-2],tokens[i-1],tokens[i])\n",
    "            else:\n",
    "                prob*=bi_prob(tokens[i-1],tokens[i])\n",
    "    l=len(tokens)-1\n",
    "    return prob**(1/l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kiểm tra xác xuất của 1 câu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=1\n",
      "prob= 0.0024390094946983173\n",
      "perplexity= 410.00250395650494\n",
      "n=2\n",
      "prob= 0.0004853876230056048\n",
      "perplexity= 2060.2091042367865\n",
      "n=3\n",
      "prob= 0.00018897930287603375\n",
      "perplexity= 5291.584765004546\n"
     ]
    }
   ],
   "source": [
    "# sent='the human body with new abilities is no longer a question'\n",
    "# sent='the human body with new from abilities is no longer a question'\n",
    "sent='A few years back from'\n",
    "print('n=1')\n",
    "pr=probLM(sent,1)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)\n",
    "\n",
    "print('n=2')\n",
    "pr=probLM(sent,2)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)\n",
    "\n",
    "print('n=3')\n",
    "pr=probLM(sent,3)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So sánh xác suất của 2 câu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob1= 0.00018894862176008524\n",
      "prob2= 0.00012480501222787032\n",
      "perplexity1= 5292.44400242165\n",
      "perplexity2= 8012.498714187771\n"
     ]
    }
   ],
   "source": [
    "# kiểm tra xem 2 xâu có xác suất hơn nhau thế nào, ví dụ cho bài toán speech to text\n",
    "sent1='the human body with new abilities is no longer a question'\n",
    "sent2='the human body with knew abilities is know longer a question'\n",
    "\n",
    "#ENTER YOU CODE HERE\n",
    "#-> tính xác suất và perplexity cho 2 câu, hiển thị kết quả để sánh\n",
    "pr1=probLM(sent1,3)\n",
    "pr2=probLM(sent2,3)\n",
    "print('prob1=',pr1)\n",
    "print('prob2=',pr2)\n",
    "perplexity1 = 1/pr1\n",
    "perplexity2 = 1/pr2\n",
    "\n",
    "print('perplexity1=',perplexity1)\n",
    "print('perplexity2=',perplexity2)\n",
    "\n",
    "#END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
