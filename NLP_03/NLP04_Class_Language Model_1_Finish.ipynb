{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Mô hình ngôn ngữ và ứng dụng cho kiểm lỗi chính tả\n",
    "\n",
    "#### Mục tiêu: xây dựng chương trình kiểm lỗi cú pháp tiếng Anh đơn giản \n",
    "\n",
    "Bài 1:  \n",
    "\n",
    "a)\tXây dựng mô hình ngôn ngữ dựa trên n-gram sử dụng phương pháp smoothing là Laplace, cho các mô hình:\n",
    "-\t1-gram\n",
    "-\t2-gram\n",
    "-\t3-gram\n",
    "\n",
    "b)\tTính xác suất của một câu và tính Perplexity của một câu dựa theo 1-gram, 2-gram, 3-gram\n",
    "\n",
    "c)\tPhân tích kết quả\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đọc file input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "[\"Here are two reasons companies fail: they only do more of the same, or they only do what's new\", 'To me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation', 'Both are necessary, but it can be too much of a good thing', 'Consider Facit', \"I'm actually old enough to remember them\"]\n"
     ]
    }
   ],
   "source": [
    "# đọc file\n",
    "filename='data/tedtalk.txt'\n",
    "lines=[]\n",
    "count=0\n",
    "#Max=-1\n",
    "Max=10000\n",
    "with open(filename,'r') as f:\n",
    "    for s in f:\n",
    "        count+=1\n",
    "        if count>Max and Max!=-1:\n",
    "            break\n",
    "        lines.append(s.strip())\n",
    "print(len(lines))\n",
    "print(lines[:5])          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cài đặt thư viện xử lý ngôn ngữ nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.5.zip (1.4 MB)\n",
      "Collecting click\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\envs\\dl\\lib\\site-packages (from nltk) (0.17.0)\n",
      "Collecting regex\n",
      "  Downloading regex-2020.11.13-cp36-cp36m-win_amd64.whl (269 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.54.1-py2.py3-none-any.whl (69 kB)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py): started\n",
      "  Building wheel for nltk (setup.py): finished with status 'done'\n",
      "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434680 sha256=1c2e91d1deba89e82171abaf4dcd3aec1e7af56de65c94acd30f5c48ac41c55c\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\de\\5e\\42\\64abaeca668161c3e2cecc24f864a8fc421e3d07a104fc8a51\n",
      "Successfully built nltk\n",
      "Installing collected packages: click, regex, tqdm, nltk\n",
      "Successfully installed click-7.1.2 nltk-3.5 regex-2020.11.13 tqdm-4.54.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thực hiện tokenize tập input\n",
    "Thêm '\\<s\\>' vào trước mỗi câu, thêm '\\</s\\>' vào sau mỗi câu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_tokens_count= 186299\n",
      "10000\n",
      "[['<s>', 'here', 'are', 'two', 'reasons', 'companies', 'fail', ':', 'they', 'only', 'do', 'more', 'of', 'the', 'same', ',', 'or', 'they', 'only', 'do', 'what', \"'s\", 'new', '</s>'], ['<s>', 'to', 'me', 'the', 'real', ',', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', ':', 'exploration', 'and', 'exploitation', '</s>'], ['<s>', 'both', 'are', 'necessary', ',', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing', '</s>'], ['<s>', 'consider', 'facit', '</s>'], ['<s>', 'i', \"'m\", 'actually', 'old', 'enough', 'to', 'remember', 'them', '</s>']]\n"
     ]
    }
   ],
   "source": [
    "# tokenize sentences \n",
    "import nltk\n",
    "sentences=[]\n",
    "all_tokens_count=0\n",
    "for line in lines:\n",
    "    tokens = nltk.word_tokenize(line.lower())\n",
    "    all_tokens_count+=len(tokens)\n",
    "    #sentences.append(tokens)\n",
    "    sentences.append(['<s>']+tokens+['</s>'])\n",
    "print('all_tokens_count=',all_tokens_count)\n",
    "print(len(sentences))\n",
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V= 12653\n",
      "n= 186299\n",
      "8059\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "# counting 1-gram \n",
    "from collections import Counter\n",
    "counter_unigram=Counter()\n",
    "for sent in sentences:\n",
    "    counter_unigram.update(sent)\n",
    "V=len(counter_unigram)\n",
    "print('V=',V)\n",
    "n=0\n",
    "for gram in counter_unigram:\n",
    "    n+=counter_unigram[gram]\n",
    "n=n-counter_unigram['<s>']-counter_unigram['</s>']\n",
    "print('n=',n)\n",
    "print(counter_unigram['the'])\n",
    "print(counter_unigram['he'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196299\n",
      "('<s>', 'here')\n",
      "('here', 'are')\n",
      "('are', 'two')\n",
      "V= 79306\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "bi_grams=[]\n",
    "for sent in sentences:\n",
    "    gram2=ngrams(sent,2)\n",
    "    bi_grams.extend(gram2)\n",
    "print(len(bi_grams))\n",
    "\n",
    "for i in range(3):\n",
    "    print(bi_grams[i])\n",
    "\n",
    "counter_bigram = Counter(bi_grams)\n",
    "print('V=',len(counter_bigram))\n",
    "print(counter_bigram[('here','are')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186299\n",
      "('<s>', 'here', 'are')\n",
      "('here', 'are', 'two')\n",
      "('are', 'two', 'reasons')\n",
      "V= 141749\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "tri_grams=[]\n",
    "for sent in sentences:\n",
    "    gram3=ngrams(sent,3)\n",
    "    tri_grams.extend(gram3)\n",
    "print(len(tri_grams))\n",
    "\n",
    "for i in range(3):\n",
    "    print(tri_grams[i])\n",
    "\n",
    "counter_trigram = Counter(tri_grams)\n",
    "print('V=',len(counter_trigram))\n",
    "print(counter_trigram[('here','are','two')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viết hàm tính xác suất cho từng loại: 1-gram, 2-gram, 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tính prob theo từng loại: 1-gram, 2-gram, 3-gram\n",
    "def uni_prob(word):\n",
    "    return max(1,counter_unigram[word])/all_tokens_count\n",
    "\n",
    "def bi_prob(word1,word2):\n",
    "    if counter_bigram[(word1,word2)]>0:\n",
    "        return counter_bigram[(word1,word2)]/counter_unigram[word1]\n",
    "    else:\n",
    "        return 0.4*uni_prob(word2)\n",
    "    \n",
    "def tri_prob(word1,word2,word3):\n",
    "    if counter_trigram[(word1,word2,word3)]>0:\n",
    "        return counter_trigram[(word1,word2,word3)]/counter_bigram[(word1,word2)]\n",
    "    else:\n",
    "        return 0.4*bi_prob(word1,word2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viết hàm tính xác xuất cho một câu, normalize theo 1 từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tính xác suất của một câu, normalize theo 1 từ \n",
    "def probLM(sent,n):\n",
    "    if n>3 or n<1: # không xét trường hợp này \n",
    "        return 0\n",
    "    tokens=nltk.word_tokenize(sent.lower())\n",
    "    tokens += ['<s>']+tokens\n",
    "    prob=1\n",
    "    for i in range(1,len(tokens)):\n",
    "        if n==1:\n",
    "            prob*=uni_prob(tokens[i])\n",
    "        elif n==2:\n",
    "            prob*=bi_prob(tokens[i-1],tokens[i])\n",
    "        elif n==3:\n",
    "            if i>=2:\n",
    "                prob*=tri_prob(tokens[i-2],tokens[i-1],tokens[i])\n",
    "            else:\n",
    "                prob*=bi_prob(tokens[i-1],tokens[i])\n",
    "    l=len(tokens)-1\n",
    "    return prob**(1/l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kiểm tra xác xuất của 1 câu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=1\n",
      "prob= 0.001493428059077296\n",
      "perplexity= 669.6003827715966\n",
      "n=2\n",
      "prob= 0.018964321328103315\n",
      "perplexity= 52.73059777351987\n",
      "n=3\n",
      "prob= 0.139268032225464\n",
      "perplexity= 7.180398717640231\n"
     ]
    }
   ],
   "source": [
    "sent='the human body with new abilities is no longer a question'\n",
    "#sent='the human body with new from abilities is no longer a question'\n",
    "#sent='A few years back from'\n",
    "print('n=1')\n",
    "pr=probLM(sent,1)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)\n",
    "\n",
    "print('n=2')\n",
    "pr=probLM(sent,2)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)\n",
    "\n",
    "print('n=3')\n",
    "pr=probLM(sent,3)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So sánh xác suất của 2 câu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob= 0.139268032225464\n",
      "perplexity= 7.180398717640231\n",
      "prob= 0.003432760555032788\n",
      "perplexity= 291.31073489349404\n"
     ]
    }
   ],
   "source": [
    "# kiểm tra xem 2 xâu có xác suất hơn nhau thế nào, ví dụ cho bài toán speech to text\n",
    "sent1='the human body with new abilities is no longer a question'\n",
    "sent2='the human body with knew abilities is know longer a question'\n",
    "pr=probLM(sent1,3)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)\n",
    "\n",
    "pr=probLM(sent2,3)\n",
    "print('prob=',pr)\n",
    "print('perplexity=',1/pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
