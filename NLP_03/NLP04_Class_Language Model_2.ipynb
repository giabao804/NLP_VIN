{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "### Mô hình ngôn ngữ và ứng dụng cho kiểm lỗi chính tả\n",
    "\n",
    "#### Mục tiêu: xây dựng chương trình kiểm lỗi cú pháp tiếng Anh đơn giản \n",
    "\n",
    "Bài 2:\n",
    "\n",
    "a)\tCải tiến mô hình bằng cách sử dụng smoothing là phương pháp interpolation theo “Stupid backoff” (Brants et al. 2007)\n",
    "\n",
    "b)\tSo sánh với kết quả bài 1\n",
    "\n",
    "c)\tDùng mô hình vừa xây dựng để sinh các từ tiếp theo với một chuỗi từ cho trước.\n",
    "\n",
    "d)\tKết hợp với hàm tính khoảng cách giữa các từ để dự đoán từ đúng cho vị trí từ sai chính tả. (from difflib import get_close_matches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đọc input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "[\"Here are two reasons companies fail: they only do more of the same, or they only do what's new\", 'To me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation', 'Both are necessary, but it can be too much of a good thing', 'Consider Facit', \"I'm actually old enough to remember them\"]\n"
     ]
    }
   ],
   "source": [
    "# đọc file\n",
    "filename='data/tedtalk.txt'\n",
    "lines=[]\n",
    "count=0\n",
    "#Max=-1\n",
    "Max=10000\n",
    "\n",
    "#ENTER YOU CODE HERE\n",
    "#-> Đọc dữ liệu trong filename theo từng line (mỗi line là 1 sentence) vào lines[], dùng biến count đếm số lượng, nếu vượt quá Max thì không đọc nữa.\n",
    ".....\n",
    "#END YOUR CODE\n",
    "\n",
    "print(len(lines))\n",
    "print(lines[:5])          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thực hiện tokenize tập input\n",
    "Thêm '\\<s\\>' vào trước mỗi câu, thêm '\\</s\\>' vào sau mỗi câu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_tokens_count= 186299\n",
      "10000\n",
      "[['<s>', 'here', 'are', 'two', 'reasons', 'companies', 'fail', ':', 'they', 'only', 'do', 'more', 'of', 'the', 'same', ',', 'or', 'they', 'only', 'do', 'what', \"'s\", 'new', '</s>'], ['<s>', 'to', 'me', 'the', 'real', ',', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', ':', 'exploration', 'and', 'exploitation', '</s>'], ['<s>', 'both', 'are', 'necessary', ',', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing', '</s>'], ['<s>', 'consider', 'facit', '</s>'], ['<s>', 'i', \"'m\", 'actually', 'old', 'enough', 'to', 'remember', 'them', '</s>']]\n"
     ]
    }
   ],
   "source": [
    "# tokenize sentences \n",
    "import nltk\n",
    "sentences=[]\n",
    "all_tokens_count=0\n",
    "\n",
    "#ENTER YOU CODE HERE\n",
    "#-> thực hiện tokenize tập input đưa vào sentences, lower trước khi tokenize\n",
    "# Đếm số lượng token vào biến all_tokens_count\n",
    "# Mỗi sentence thêm ký tự '<s>' vào đầu, '</s>' vào cuối\n",
    ".....\n",
    "#END YOUR CODE\n",
    "\n",
    "    \n",
    "print('all_tokens_count=',all_tokens_count)\n",
    "print(len(sentences))\n",
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V= 12653\n",
      "n= 186299\n",
      "8059\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "# counting 1-gram \n",
    "from collections import Counter\n",
    "counter_unigram=Counter()\n",
    "\n",
    "#ENTER YOU CODE HERE\n",
    "#-> Dùng counter_unigram để đếm token 1-gram cho tập sentences\n",
    ".....\n",
    "#END YOUR CODE\n",
    "\n",
    "V=len(counter_unigram)\n",
    "print('V=',V)\n",
    "n=0\n",
    "for gram in counter_unigram:\n",
    "    n+=counter_unigram[gram]\n",
    "n=n-counter_unigram['<s>']-counter_unigram['</s>']\n",
    "print('n=',n)\n",
    "print(counter_unigram['the'])\n",
    "print(counter_unigram['he'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196299\n",
      "('<s>', 'here')\n",
      "('here', 'are')\n",
      "('are', 'two')\n",
      "V= 79306\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "bi_grams=[]\n",
    "\n",
    "#ENTER YOU CODE HERE\n",
    "#-> Dùng ngrams để đếm token 2-gram cho tập sentences\n",
    ".....\n",
    "#END YOUR CODE\n",
    "\n",
    "print(len(bi_grams))\n",
    "\n",
    "for i in range(3):\n",
    "    print(bi_grams[i])\n",
    "\n",
    "counter_bigram = Counter(bi_grams)\n",
    "print('V=',len(counter_bigram))\n",
    "print(counter_bigram[('here','are')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186299\n",
      "('<s>', 'here', 'are')\n",
      "('here', 'are', 'two')\n",
      "('are', 'two', 'reasons')\n",
      "V= 141749\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "tri_grams=[]\n",
    "\n",
    "#ENTER YOU CODE HERE\n",
    "#-> Dùng ngrams để đếm token 3-gram cho tập sentences\n",
    ".....\n",
    "#END YOUR CODE\n",
    "\n",
    "print(len(tri_grams))\n",
    "\n",
    "for i in range(3):\n",
    "    print(tri_grams[i])\n",
    "\n",
    "counter_trigram = Counter(tri_grams)\n",
    "print('V=',len(counter_trigram))\n",
    "print(counter_trigram[('here','are','two')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xây dựng dict từ 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_dict={}\n",
    "set_tri_grams = set(tri_grams)\n",
    "for gram in set_tri_grams:\n",
    "    key=(gram[0],gram[1])\n",
    "    if key in tri_dict.keys():\n",
    "        tri_dict[key].append(gram[2])\n",
    "    else:\n",
    "        tri_dict[key]=[gram[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75672\n",
      "[('they', 'did'), ('in', 'north'), ('becoming', 'so')]\n",
      "here are: ?\n",
      "['some', 'all', 'two', 'wondering', 'the', 'worth']\n"
     ]
    }
   ],
   "source": [
    "print(len(tri_dict))\n",
    "print(list(tri_dict.keys())[:3])\n",
    "print('here are: ?')\n",
    "print(tri_dict[('here','are')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dùng mô hình vừa xây dựng để sinh các từ tiếp theo với một chuỗi từ cho trước"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'here', 'are', 'the', 'most']\n",
      "important\n",
      "['important', 'powerful', 'pressing', '</s>', 'for', 'beautiful', 'dangerous', 'famous', 'extraordinary', 'interesting', 'valuable', 'difficult', 'data-savvy', 'advanced', 'compassionate', 'positive', 'followed', 'revolutionary', 'magnificent', 'uncertain', 'troubled', 'fundamental', 'severe', 'populated', 'universal', 'potential', 'resource-efficient', 'essential', 'primordial', 'ardent', 'basic', 'part', 'impoverished', 'sophisticated', 'consumed', 'trivial', 'value', 'productive', 'successful', 'accessibly', 'evil', 'destructive', 'was', 'exciting', 'embarrassing', 'intimate', 'good', 'densely', 'amazing', 'energy-intensive', 'immaterial', 'incredible', 'remote', ':', 'promising', 'relevant', 'common', 'mysterious', 'cars', 'evolutionarily-conserved', 'unassuming', 'thrilling', 'extreme', 'demanding', 'risky', 'vivid', 'ambitious', 'incarcerated', 'critical', 'prestigious', 'violent', 'inspiring', 'by', 'used', 'heartbreaking', 'controversial', 'satisfied', 'fragile', 'profound', 'liberal', 'cryptic', ',', 'sacred', 'unique', 'carbon-intensive', 'excellent']\n"
     ]
    }
   ],
   "source": [
    "# dự đoán từ tiếp theo\n",
    "seq='here are the most'\n",
    "tokens=nltk.word_tokenize(seq.lower())\n",
    "tokens=['<s>']+tokens\n",
    "print(tokens)\n",
    "i=len(tokens)-1\n",
    "key=(tokens[i-1],tokens[i])\n",
    "#print(tri_dict[key])\n",
    "dict_nextword={}\n",
    "\n",
    "\n",
    "#ENTER YOU CODE HERE\n",
    "#-> viết đoạn lệnh để dự đoán từ tiếp theo vào dict_nextword, dùng counter_trigram\n",
    "\n",
    "#END YOUR CODE\n",
    "    \n",
    "sorted_dict=sorted(dict_nextword,key=dict_nextword.__getitem__,reverse=True)\n",
    "\n",
    "#print(dict_nextword)\n",
    "print(sorted_dict[0])\n",
    "print(sorted_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dự đoán chuỗi K từ tiếp theo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'here', 'are', 'the']\n",
      "here are the ones that need to do it </s>\n"
     ]
    }
   ],
   "source": [
    "# dự đoán chuỗi K từ tiếp theo\n",
    "seq='here are the'\n",
    "tokens=nltk.word_tokenize(seq.lower())\n",
    "tokens=['<s>']+tokens\n",
    "print(tokens)\n",
    "N=10\n",
    "count=0\n",
    "while count<N:\n",
    "    count+=1\n",
    "    i=len(tokens)-1\n",
    "    key=(tokens[i-1],tokens[i])\n",
    "    #print(tri_dict[key])\n",
    "    dict_nextword={}\n",
    "    if not (key in tri_dict.keys()):\n",
    "        break\n",
    "    \n",
    "    #ENTER YOU CODE HERE\n",
    "    #-> viết đoạn lệnh để dự đoán chuỗi K (K=N) từ tiếp theo vào dict_nextword, dùng counter_trigram\n",
    "\n",
    "    #END YOUR CODE\n",
    "    \n",
    "    sorted_dict=sorted(dict_nextword,key=dict_nextword.__getitem__,reverse=True)\n",
    "    \n",
    "    #print(dict_nextword)\n",
    "    #print(sorted_dict[0])\n",
    "    tokens.append(sorted_dict[0])\n",
    "    seq+= ' '+sorted_dict[0]\n",
    "\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kết hợp với hàm tính khoảng cách giữa các từ để dự đoán từ đúng cho vị trí từ sai chính tả. (from difflib import get_close_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'here', 'are', 'the', 'most']\n",
      "['important', 'powerful', 'pressing', '</s>', 'for', 'beautiful', 'dangerous', 'famous', 'extraordinary', 'interesting']\n",
      "['important', 'beautiful', 'revolutionary', 'impoverished', 'intimate', 'part', 'ambitious', 'primordial']\n"
     ]
    }
   ],
   "source": [
    "# for spelling \n",
    "from difflib import get_close_matches\n",
    "#get_close_matches('appel', ['ape', 'apple', 'peach', 'puppy'])\n",
    "\n",
    "# dự đoán từ tiếp theo\n",
    "seq='here are the most'\n",
    "#errword='impotant'\n",
    "errword='beutimport'\n",
    "tokens=nltk.word_tokenize(seq.lower())\n",
    "tokens=['<s>']+tokens\n",
    "print(tokens)\n",
    "\n",
    "i=len(tokens)-1\n",
    "key=(tokens[i-1],tokens[i])\n",
    "#print(tri_dict[key])\n",
    "dict_nextword={}\n",
    "\n",
    "#ENTER YOU CODE HERE\n",
    "#-> viết đoạn lệnh để dự đoán từ đúng\n",
    "# dùng hàm get_close_matches với n = 10, cutoff=0.4\n",
    "#closed_words=get_close_matches(.....)\n",
    "#END YOUR CODE\n",
    "\n",
    "\n",
    "print(closed_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
