{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giabao804/NLP_VIN/blob/main/NLP_Th%E1%BB%B1c_h%C3%A0nh_tr%C3%AAn_l%E1%BB%9Bp_10_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv_0feSa73x6"
      },
      "source": [
        "## **Bài thực hành bài 12**: Ứng dụng mô hình sequence2sequence cho bài toán dịch máy (machine translation)\n",
        "\n",
        "Tổng quan: Ở bài tập này chúng ta sẽ lần lượt thực hành các bước để xây dựng một hệ thống học máy cho bài toán dịch máy dựa vào mạng seq2seq: tải và tiền xử lý dữ liệu song ngữ, tạo dữ liệu huấn luyện, xây dựng mô hình seq2seq với attention, hiển thị dữ liệu attention và dịch câu mới trên dữ liệu thực tế. Bài tập yêu cầu các kiến thức về lập trình Python với các thư viện: keras, numpy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QplquiDdApB0"
      },
      "source": [
        "**1. Tải và tiền xử lý dữ liệu**\n",
        "\n",
        "Nội dung chính:\n",
        "1.   Tải dữ liệu song ngữ\n",
        "2.   Xóa các kí tự đặc biệt trong câu\n",
        "3.   Tách từ (word tokenizer)\n",
        "4.   Tạo từ điển\n",
        "5.   Thêm các token đặc biệt vào câu như : start, end, pad\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5OxzO0WtOXp"
      },
      "source": [
        "- Import các thư viện cần thiết"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRPUxQvLtSwx"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"tuannguyenvananh/iwslt15-englishvietnamese\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK3U80lscazQ",
        "outputId": "d93fdf14-1019-4c0f-81bb-120e90f90247"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.3)\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/tuannguyenvananh/iwslt15-englishvietnamese/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoEhyJ6owUcV"
      },
      "source": [
        "- Dowload dataset\n",
        "\n",
        "Trong bài thực hành này chúng ra sẽ sử dụng bộ song ngữ Vietnamese - English gồm 133k cặp câu song ngữ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMCE8jiawi3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece1b26d-cf68-49d5-fbf2-c107be355149"
      },
      "source": [
        "\n",
        "OUT_DIR = \"/content/data_iwslt15/IWSLT'15 en-vi/\"\n",
        "!mkdir $OUT_DIR\n",
        "# SITE_PREFIX=\"https://nlp.stanford.edu/projects/nmt/data\"\n",
        "# # Download iwslt15 small dataset from standford website.\n",
        "# print (\"Download training dataset train.en and train.vi.\")\n",
        "# !curl -o \"$OUT_DIR/train.en\" \"$SITE_PREFIX/iwslt15.en-vi/train.en\"\n",
        "# !curl -o \"$OUT_DIR/train.vi\" \"$SITE_PREFIX/iwslt15.en-vi/train.vi\"\n",
        "\n",
        "# print (\"Download dev dataset tst2012.en and tst2012.vi.\")\n",
        "# !curl -o \"$OUT_DIR/tst2012.en\" \"$SITE_PREFIX/iwslt15.en-vi/tst2012.en\"\n",
        "# !curl -o \"$OUT_DIR/tst2012.vi\" \"$SITE_PREFIX/iwslt15.en-vi/tst2012.vi\"\n",
        "\n",
        "# print (\"Download test dataset tst2013.en and tst2013.vi.\")\n",
        "# !curl -o \"$OUT_DIR/tst2013.en\" \"$SITE_PREFIX/iwslt15.en-vi/tst2013.en\"\n",
        "# !curl -o \"$OUT_DIR/tst2013.vi\" \"$SITE_PREFIX/iwslt15.en-vi/tst2013.vi\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: unexpected EOF while looking for matching `''\n",
            "/bin/bash: -c: line 2: syntax error: unexpected end of file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da97Qlc91-9i"
      },
      "source": [
        "- Viết hàm tiền xử lý dữ liệu. Hàm này xử lý dữ liệu đầu vào như xóa bỏ các kí tự đặc biệt, lowercase, ... Ngoài ra ta cũng thêm token bắt đầu và kết thúc câu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-YZuigf2OLg"
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = \"<start> \"+sentence+\" <end>\"\n",
        "  return sentence\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUubFKSOzxAE"
      },
      "source": [
        "- Load data và xem thử data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcr-jjng0G9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7bb8930-8338-4025-cf63-24c45787887b"
      },
      "source": [
        "def load_data(source_file, target_file, number_of_examples):\n",
        "  # source_data = [preprocess_sentence(source_sentence)\n",
        "  #                 for source_sentence in open(source_file, \"r\").readlines()[:number_of_examples]]\n",
        "  # target_data = [preprocess_sentence(target_sentence)\n",
        "  #                 for target_sentence in open(target_file, \"r\").readlines()[:number_of_examples]]\n",
        "  max_len = 50\n",
        "  source_sents = open(source_file, \"r\").readlines()\n",
        "  target_sents = open(target_file, \"r\").readlines()\n",
        "  assert len(source_sents) == len(target_sents)\n",
        "\n",
        "  source_data, target_data = [], []\n",
        "  for source_sentence, target_sentence in zip(source_sents[:number_of_examples],\n",
        "                                              target_sents[:number_of_examples]):\n",
        "    if len(source_sentence.strip().split()) > max_len or len(target_sentence.strip().split()) > max_len:\n",
        "      continue\n",
        "    source_data.append(preprocess_sentence(source_sentence))\n",
        "    target_data.append(preprocess_sentence(target_sentence))\n",
        "\n",
        "  return source_data, target_data\n",
        "\n",
        "train_src, train_trg = load_data(OUT_DIR+\"/train.en.txt\", OUT_DIR+\"/train.vi.txt\", 1000)\n",
        "print(len(train_src), len(train_trg))\n",
        "print(train_src[1])\n",
        "print(train_trg[1])\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "929 929\n",
            "<start> I &apos;d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .\n",
            " <end>\n",
            "<start> Tôi muốn cho các bạn biết về sự to lớn của những nỗ lực khoa học đã góp phần làm nên các dòng tít bạn thường thấy trên báo .\n",
            " <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0OhXShZ1X0B"
      },
      "source": [
        "- Viết hàm tách từ (tokenizer). Nhiều ngôn ngữ có thể phân tách các từ bằng dấu cách (space) như tiếng Anh, tiếng Việt, ... Nhưng 1 số ngôn ngữ không có dấu phân tách giữa các từ như tiếng Nhật, tiếng Trung Quốc. Vì vậy, ta cần có tách từ để phân tách các từ trong câu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sD8Z74u11uJ"
      },
      "source": [
        "def tokenizer(sentences):\n",
        "  tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "  sent_tensors = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "\n",
        "  sent_tensors = tf.keras.preprocessing.sequence.pad_sequences(sent_tensors,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return sent_tensors, tokenizer\n",
        "\n",
        "def create_data(source_path, target_path, number_of_examples):\n",
        "  # creating cleaned input, output pairs\n",
        "  source_data, target_data = load_data(source_path, target_path, number_of_examples)\n",
        "  source_tensors, source_tokenizer = tokenizer(source_data)\n",
        "  target_tensors, target_tokenizer = tokenizer(target_data)\n",
        "\n",
        "  return source_tensors, target_tensors, source_tokenizer, target_tokenizer\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGNuizCe_mMk"
      },
      "source": [
        "- Giới hạn số dữ liệu huấn luyện. Để kiểm tra xem chương trình chạy có đúng hay không, ban đầu ta có thể chạy thử với lượng nhỏ dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk_TG19Y_23y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfd1c4ec-1f6c-4eb6-b606-7bc12b583940"
      },
      "source": [
        "number_of_examples = 50000\n",
        "train_src_tensors, train_tgt_tensors, train_src_tokenizer, train_tgt_tokenizer = create_data(OUT_DIR+\"/train.en.txt\", OUT_DIR+\"/train.vi.txt\", number_of_examples)\n",
        "valid_src_tensors, valid_tgt_tensors, _, _ = create_data(OUT_DIR+\"/tst2012.en.txt\", OUT_DIR+\"/tst2012.vi.txt\", -1)\n",
        "test_src_tensors, test_tgt_tensors, _, _ = create_data(OUT_DIR+\"/tst2013.en.txt\", OUT_DIR+\"/tst2013.vi.txt\", -1)\n",
        "\n",
        "max_length_source, max_length_target = train_src_tensors.shape[1], train_tgt_tensors.shape[1]\n",
        "\n",
        "print(len(train_src_tensors))\n",
        "# print(train_src_tensors[0])\n",
        "\n",
        "# View source dictionary\n",
        "print(len(train_src_tokenizer.word_index))\n",
        "for t in train_src_tensors[0][:5]:\n",
        "  print(t, train_src_tokenizer.index_word[t])\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45952\n",
            "26370\n",
            "1 <start>\n",
            "7615 rachel\n",
            "14913 pike\n",
            "56 :\n",
            "5 the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB_awkp8A4Zh"
      },
      "source": [
        "**2. Tạo dữ liệu huấn luyện**\n",
        "\n",
        "Nội dung chính: Tạo dữ liệu huấn luyện theo batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24QafWymFXIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0482e1-5fea-423c-a904-6b563d422c41"
      },
      "source": [
        "BUFFER_SIZE = len(train_src_tensors)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(train_src_tensors)//BATCH_SIZE\n",
        "\n",
        "vocab_src_size = len(train_src_tokenizer.word_index)+1\n",
        "vocab_tgt_size = len(train_tgt_tokenizer.word_index)+1\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_src_tensors, train_tgt_tensors)).shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(train_dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 52]), TensorShape([64, 52]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OhJaiJfBDj4"
      },
      "source": [
        "**3. Viết mô hình seq2seq với attention**\n",
        "\n",
        "Nội dung chính : Viết Encoder, BahdanauAttention, Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx4JHLpcGz9E"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_state_size, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.hidden_state_size = hidden_state_size\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.rnn = tf.keras.layers.SimpleRNN(self.hidden_state_size,\n",
        "                                     return_sequences=True,\n",
        "                                     return_state=True,\n",
        "                                     recurrent_initializer='glorot_uniform')\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    # YOUR CODE HERE\n",
        "    x = self.embedding(x)\n",
        "    # The GRU with return_sequences and return_state might return three values.\n",
        "    # Adjust the unpacking accordingly\n",
        "    output, state = self.rnn(x, initial_state = hidden) #Only unpack the last two values\n",
        "    # YOUR CODE HERE\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.hidden_state_size))"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6eSgd5XHlg2"
      },
      "source": [
        "- Tạo Encoder và test thử  Encoder đó với 1 batch dữ liệu và in ra shape của encoder output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzvgvWWpG2Uj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887207aa-1ec9-4f21-e86c-a901c42dcba6"
      },
      "source": [
        "embedding_dim = 512\n",
        "hidden_state_size = 512\n",
        "\n",
        "\n",
        "encoder = Encoder(vocab_src_size, embedding_dim, hidden_state_size, BATCH_SIZE)\n",
        "\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n",
        "#"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 52, 512)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_0xRRWwIX5U"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # Ensure that query has shape (batch_size, hidden_size)\n",
        "    if len(query.shape) == 1:\n",
        "        query = tf.expand_dims(query, 0)  # Add batch dimension if missing\n",
        "\n",
        "    # Expand query to (batch_size, 1, hidden size)\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # Apply W1 to query and W2 to values\n",
        "    W1_query = self.W1(query_with_time_axis)\n",
        "    W2_values = self.W2(values)\n",
        "\n",
        "    # Broadcast addition along the time axis\n",
        "    score = self.V(tf.nn.tanh(W1_query + W2_values))\n",
        "\n",
        "    # Compute softmax along the sequence length to get attention weights\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # Compute the context vector as a weighted sum of values\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJedH3LrIc2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab43f6e0-8b97-4dd2-8bb9-a9176c80c6ba"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch size, units) (64, 512)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 52, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iERUOAAnIsDR"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_state_size, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    # YOUR CODE HERE\n",
        "    self.batch_sz = batch_sz\n",
        "    self.hidden_state_size = hidden_state_size\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.rnn = tf.keras.layers.SimpleRNN(self.hidden_state_size,\n",
        "                                     return_sequences=True,\n",
        "                                     return_state=True,\n",
        "                                     recurrent_initializer='glorot_uniform')\n",
        "\n",
        "\n",
        "\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.hidden_state_size)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.rnn(x, initial_state=hidden)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QreiGFlAJKFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c0b500-46ac-460c-ab69-999ef400dba3"
      },
      "source": [
        "decoder = Decoder(vocab_tgt_size, embedding_dim, hidden_state_size, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 12469)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knp_Kg5fBW9V"
      },
      "source": [
        "**4. Định nghĩa hàm tối ưu (optimizer) và hàm lỗi (loss function)**\n",
        "\n",
        "Nội dung chính: Sử dụng hàm tối ưu Adam và hàm lỗi CrossEntropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbmLqm3c8tgk"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  # YOUR CODE HERE\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  # YOUR CODE HERE\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIAuA4oEBkIR"
      },
      "source": [
        "**5. Huấn luyện mô hình (Training)**\n",
        "\n",
        "Nội dung chính: Sử dụng dữ liệu, mô hình seq2seq + attention đã build ở trên để huấn luyện mô hình."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-PoKhgO9YgL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b7f73b0-383e-43cd-f689-bad4665ee733"
      },
      "source": [
        "@tf.function\n",
        "def train_step(source, target, enc_hidden):\n",
        "  loss = 0\n",
        "  # YOUR CODE HERE\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(source, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([train_tgt_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, target.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(target[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(target[:, t], 1)\n",
        "  # YOUR CODE HERE\n",
        "\n",
        "\n",
        "  batch_loss = (loss / int(target.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss\n",
        "\n",
        "\n",
        "checkpoint_dir = './model_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "\n",
        "EPOCHS = 1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (source, target)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(source, target, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 1 epochs\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "\n",
        "\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 3.7157\n",
            "Epoch 1 Batch 100 Loss 2.5290\n",
            "Epoch 1 Batch 200 Loss 2.7285\n",
            "Epoch 1 Batch 300 Loss 2.5458\n",
            "Epoch 1 Batch 400 Loss 1.9934\n",
            "Epoch 1 Batch 500 Loss 2.0336\n",
            "Epoch 1 Batch 600 Loss 2.1701\n",
            "Epoch 1 Batch 700 Loss 1.9004\n",
            "Epoch 1 Loss 2.3825\n",
            "Time taken for 1 epoch 282.44951248168945 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0dl31L1CAZT"
      },
      "source": [
        "**6. Dịch (Translate)**\n",
        "\n",
        "Nội dung chính: Sử dụng mô hình đã được huấn luyện để  dịch dữ liệu mới"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eLxiM8JHdjh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "55bf7cd6-1074-4f03-9edd-da26585e810a"
      },
      "source": [
        "def evaluate(source_sentence):\n",
        "  attention_plot = np.zeros((max_length_target, max_length_source))\n",
        "\n",
        "  source_sentence = preprocess_sentence(source_sentence)\n",
        "\n",
        "  inputs = [train_src_tokenizer.word_index[i] for i in source_sentence.lower().split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_source,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  # YOUR CODE HERE\n",
        "  hidden = None\n",
        "  enc_out, enc_hidden = None\n",
        "\n",
        "  dec_hidden = None\n",
        "  dec_input = None\n",
        "\n",
        "  for t in range(max_length_target):\n",
        "    predictions, dec_hidden, attention_weights = None\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = None\n",
        "    attention_plot[t] = None\n",
        "\n",
        "    predicted_id = None\n",
        "\n",
        "    result += None\n",
        "\n",
        "  # YOUR CODE HERE\n",
        "\n",
        "\n",
        "    if train_tgt_tokenizer.index_word[predicted_id] == '<end>':\n",
        "      return result, source_sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, source_sentence, attention_plot\n",
        "\n",
        "source_sentence = \"How are you ?\"\n",
        "result, source_sentence, attention_plot = evaluate(source_sentence)\n",
        "print('Input: %s' % (source_sentence))\n",
        "print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "cannot unpack non-iterable NoneType object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-a161b69d8f01>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0msource_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"How are you ?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msource_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted translation: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-a161b69d8f01>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(source_sentence)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mdec_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlIHB7pICSJV"
      },
      "source": [
        "**7. Hiển thị attention (Plot attention)**\n",
        "\n",
        "Nội dung chính : Hiển thị attention để hiểu rõ hơn vai trò của attention trong mô hình seq2seq\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_GAnSPZMZyl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "ffe71606-3a2c-47da-d663-bed8c7e42ff6"
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "attention_plot = attention_plot[:len(result.split(' ')), :len(source_sentence.split(' '))]\n",
        "plot_attention(attention_plot, source_sentence.split(' '), result.split(' '))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZnHpT-LOI0h"
      },
      "source": [
        "**8. Tính điểm BLEU**\n",
        "\n",
        "BLEU là 1 độ đo rất phổ biến để đánh giá chất lượng của 1 hệ thống dịch máy. Bạn có thể download script tính multi-bleu tại github của mosesdecoder : https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl\n",
        "\n",
        "Trong bài này, chúng tôi sẽ sử dụng hàm tính bleu có sẵn trong python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mka8zUX8PBLE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f200d63d-7c28-4341-be50-83d620a91f3b"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "reference = [['this', 'is', 'a', 'test']]\n",
        "candidate = ['this', 'is', 'a', 'test']\n",
        "score = sentence_bleu(reference, candidate)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4Ygurw3QNhq"
      },
      "source": [
        "Bài tập : Hãy sử dụng BLEU để đánh giá mô hình bạn vừa huấn luyện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKzuLyUTQZWo"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}