{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMOgCx5Hcrb6"
      },
      "source": [
        "# Named Entity Recognition\n",
        "\n",
        "### Dự đoán named entities trong cơ sở dữ liệu GMB(Groningen Meaning Bank)\n",
        "\n",
        "Sử dụng Sequence Tagging với mô hình LSTM-CRF để trích xuất tên các thực thể trong văn bản\n",
        "nhãn các thực thể được mã hóa sử dụng các ký hiệu BIO, trong đó mỗi nhãn thực thể được gán với ký hiệu B hoặc I. B- ký hiệu là bắt đầu (begining) và I- là bên trong (inside) một thực thể. Các ký hiệu này dùng để xác định các thực thể có nhiều từ, ví dụ với câu :\"World War II\", các nhãn là:(B-eve, I-eve, I-eve). Các từ khác, không thuộc thực thể được gán nhãn là O.\n",
        "Tag | Label meaning | Example Given\n",
        "------------ | ------------- |\n",
        "geo | Geographical Entity | London\n",
        "org | Organization | ONU\n",
        "per | Person | Bush\n",
        "gpe | Geopolitical Entity | British\n",
        "tim | Time indicator | Wednesday\n",
        "art | Artifact | Chrysler\n",
        "eve | Event | Christmas\n",
        "nat | Natural Phenomenon | Hurricane\n",
        "O | No-Label | the\n",
        "\n",
        "Chúng ta sẽ thực hiện:\n",
        "- Preprocess text data for NLP\n",
        "- Build and train a Bi-directional LSTM-CRF model using Keras and Tensorflow\n",
        "- Evaluate our model on the test set\n",
        "- Run the model on your own sentences!\n",
        "Mô hình:\n",
        "<img src=\"https://raw.githubusercontent.com/floydhub/named-entity-recognition-template/master/images/bilstm-crf.png\" width=\"400\" height=\"400\" align=\"center\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BFTLP-qucrb9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiJZm5DYcrb-"
      },
      "source": [
        "## Các tham số"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g2L37-owcrb-"
      },
      "outputs": [],
      "source": [
        "# Hyperparams if GPU is available\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    BATCH_SIZE = 512  # Number of examples used in each iteration\n",
        "    EPOCHS = 5  # Number of passes through entire dataset\n",
        "    MAX_LEN = 75  # Max length of review (in words)\n",
        "    EMBEDDING = 40  # Dimension of word embedding vector\n",
        "\n",
        "\n",
        "# Hyperparams for CPU training\n",
        "else:\n",
        "    BATCH_SIZE = 32\n",
        "    EPOCHS = 5\n",
        "    MAX_LEN = 75\n",
        "    EMBEDDING = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfwWsue3crb_"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "ArRnZLqrcrb_",
        "outputId": "a330cf77-aad5-4b80-a55c-c180a0a52868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ac20cace3430>:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  data = data.fillna(method=\"ffill\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences:  47959\n",
            "Number of words in the dataset:  35177\n",
            "Tags: ['I-per', 'I-tim', 'I-geo', 'O', 'I-nat', 'B-org', 'I-org', 'B-eve', 'B-tim', 'B-art', 'I-gpe', 'B-gpe', 'I-art', 'B-nat', 'B-geo', 'B-per', 'I-eve']\n",
            "Number of Labels:  17\n",
            "What the dataset looks like:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sentence #           Word  POS    Tag\n",
              "0  Sentence: 1      Thousands  NNS      O\n",
              "1  Sentence: 1             of   IN      O\n",
              "2  Sentence: 1  demonstrators  NNS      O\n",
              "3  Sentence: 1           have  VBP      O\n",
              "4  Sentence: 1        marched  VBN      O\n",
              "5  Sentence: 1        through   IN      O\n",
              "6  Sentence: 1         London  NNP  B-geo\n",
              "7  Sentence: 1             to   TO      O\n",
              "8  Sentence: 1        protest   VB      O\n",
              "9  Sentence: 1            the   DT      O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75ac9258-0b96-42a9-b1b1-f691b60b8240\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>London</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>protest</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75ac9258-0b96-42a9-b1b1-f691b60b8240')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-75ac9258-0b96-42a9-b1b1-f691b60b8240 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-75ac9258-0b96-42a9-b1b1-f691b60b8240');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-54ab06ad-bae3-4a5a-b09c-aaa91ed7f7ff\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-54ab06ad-bae3-4a5a-b09c-aaa91ed7f7ff')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-54ab06ad-bae3-4a5a-b09c-aaa91ed7f7ff button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# đọc dữ liệu csv với pandas\n",
        "data = pd.read_csv(\"/content/ner_dataset.csv\", encoding=\"latin1\")\n",
        "data = data.fillna(method=\"ffill\")\n",
        "\n",
        "print(\"Number of sentences: \", len(data.groupby(['Sentence #'])))\n",
        "\n",
        "words = list(set(data[\"Word\"].values))\n",
        "n_words = len(words)\n",
        "print(\"Number of words in the dataset: \", n_words)\n",
        "\n",
        "tags = list(set(data[\"Tag\"].values))\n",
        "print(\"Tags:\", tags)\n",
        "n_tags = len(tags)\n",
        "print(\"Number of Labels: \", n_tags)\n",
        "\n",
        "print(\"What the dataset looks like:\")\n",
        "# Show the first 10 rows\n",
        "data.head(n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOZ9ypgccrb_",
        "outputId": "e9d7c41e-b4d1-48ec-a240-b3b421249500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is what a sentence looks like:\n",
            "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-4eb213779afa>:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n"
          ]
        }
      ],
      "source": [
        "class SentenceGetter(object):\n",
        "    \"\"\"Class to Get the sentence in this format:\n",
        "    [(Token_1, Part_of_Speech_1, Tag_1), ..., (Token_n, Part_of_Speech_1, Tag_1)]\"\"\"\n",
        "    def __init__(self, data):\n",
        "        \"\"\"Args:\n",
        "            data is the pandas.DataFrame which contains the above dataset\"\"\"\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "\n",
        "    def get_next(self):\n",
        "        \"\"\"Return one sentence\"\"\"\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "getter = SentenceGetter(data)\n",
        "sent = getter.get_next()\n",
        "print('This is what a sentence looks like:')\n",
        "print(sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IRhmaS7crcA"
      },
      "source": [
        "As you can see from the output Cell above, each sentence in the dataset is represented as a list of tuple: [`(Token_1, PoS_1, Tag_1)`, ..., `(Token_n, PoS_n, Tag_n)`]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "R2WUzS0fcrcA",
        "outputId": "8276a255-9393-40b6-9f94-3b5065aff262"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get all the sentences\n",
        "sentences = getter.sentences\n",
        "\n",
        "# Plot sentence by lenght\n",
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.title('Token per sentence')\n",
        "plt.xlabel('Len (number of token)')\n",
        "plt.ylabel('# samples')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_yekz3ZcrcA"
      },
      "source": [
        "## Tiền xử lý dữ liệu\n",
        "\n",
        "-Sử dụng từ điển `word2idx` để chuyển 1 từ thành 1 số nguyên ID và tương tự từ điển `tag2idx` cho nhãn\n",
        "- Padding tất cả các câu có cùng số từ `MAX_LEN`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SjTEngguuIl",
        "outputId": "0ea38e2d-6172-48d1-9ed6-0275982a259b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.6.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zfcb3K6kcrcB",
        "outputId": "c21f1e0f-3157-4522-f393-e12179cd5625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word Obama is identified by the index: 21179\n",
            "The labels B-geo(which defines Geopraphical Enitities) is identified by the index: 15\n",
            "Raw Sample:  Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
            "Raw Label:  O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n",
            "After processing, sample: [15722 17559 26009 32503 13045 17545 30905 31707  2975 22376 33539 21524\n",
            " 11611  1758  2085 22376 30705 17559 13249 29096 21327 17819 22612 28031\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n",
            "After processing, labels: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# Vocabulary Key:word -> Value:token_index\n",
        "# The first 2 entries are reserved for PAD and UNK\n",
        "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
        "word2idx[\"UNK\"] = 1 # Unknown words\n",
        "word2idx[\"PAD\"] = 0 # Padding\n",
        "\n",
        "# Vocabulary Key:token_index -> Value:word\n",
        "idx2word = {i: w for w, i in word2idx.items()}\n",
        "\n",
        "# Vocabulary Key:Label/Tag -> Value:tag_index\n",
        "# The first entry is reserved for PAD\n",
        "tag2idx = {t: i+1 for i, t in enumerate(tags)}\n",
        "tag2idx[\"PAD\"] = 0\n",
        "\n",
        "# Vocabulary Key:tag_index -> Value:Label/Tag\n",
        "idx2tag = {i: w for w, i in tag2idx.items()}\n",
        "\n",
        "print(\"The word Obama is identified by the index: {}\".format(word2idx[\"Obama\"]))\n",
        "print(\"The labels B-geo(which defines Geopraphical Enitities) is identified by the index: {}\".format(tag2idx[\"B-geo\"]))\n",
        "\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# Biểu diễn vector cho các câu, mỗi từ --> 1 số nguyên, câu => vector\n",
        "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
        "# Padding các câu về cùng chiều dài MAXLEN\n",
        "X = pad_sequences(maxlen=MAX_LEN, sequences=X, padding=\"post\", value=word2idx[\"PAD\"])\n",
        "\n",
        "# tương tự với các nhãn (Tag/Label)\n",
        "# Convert Tag/Label to tag_index\n",
        "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
        "# Padding each sentence to have the same lenght\n",
        "y = pad_sequences(maxlen=MAX_LEN, sequences=y, padding=\"post\", value=tag2idx[\"PAD\"])\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "# One-Hot encode\n",
        "y = [to_categorical(i, num_classes=n_tags+1) for i in y]  # n_tags+1(PAD)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n",
        "X_tr.shape, X_te.shape, np.array(y_tr).shape, np.array(y_te).shape\n",
        "\n",
        "print('Raw Sample: ', ' '.join([w[0] for w in sentences[0]]))\n",
        "print('Raw Label: ', ' '.join([w[2] for w in sentences[0]]))\n",
        "print('After processing, sample:', X[0])\n",
        "print('After processing, labels:', y[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK3e3ZQGwFP1",
        "outputId": "b7e9975c-bab3-4675-d28d-36d572ede3d7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-jgoch19n\n",
            "  Running command git clone --filter=blob:none --quiet https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-jgoch19n\n",
            "  warning: redirecting to https://github.com/keras-team/keras-contrib.git/\n",
            "  Resolved https://www.github.com/keras-team/keras-contrib.git to commit 3fc5ef709e061416f4bc8a92ca3750c824b5d2b0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_contrib==2.0.8) (3.6.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras_contrib==2.0.8) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras_contrib==2.0.8) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras_contrib==2.0.8) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras_contrib==2.0.8) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras_contrib==2.0.8) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras_contrib==2.0.8) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras_contrib==2.0.8) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras->keras_contrib==2.0.8) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras_contrib==2.0.8) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_contrib==2.0.8) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_contrib==2.0.8) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_contrib==2.0.8) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf2crf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbwPtdmQ1o1f",
        "outputId": "03f19cf3-0234-48b8-b464-f3933f590d20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf2crf in /usr/local/lib/python3.10/dist-packages (0.1.33)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tf2crf) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-addons>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from tf2crf) (0.23.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.6.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.26.4)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons>=0.8.2->tf2crf) (2.13.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.1.0->tf2crf) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.1.0->tf2crf) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.1.0->tf2crf) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.1.0->tf2crf) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.1.0->tf2crf) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.1.0->tf2crf) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.1.0->tf2crf) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.1.0->tf2crf) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.1.0->tf2crf) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.1.0->tf2crf) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.1.0->tf2crf) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow>=2.1.0->tf2crf) (3.0.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=2.1.0->tf2crf) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=2.1.0->tf2crf) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow>=2.1.0->tf2crf) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "Cg8IlTUmcrcC",
        "outputId": "52f4dd81-91f8-4a15-ecf9-e4ced68ff01d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Exception encountered when calling CRF.call().\n\n\u001b[1mmodule 'keras.backend' has no attribute 'dot'\u001b[0m\n\nArguments received by CRF.call():\n  • X=tf.Tensor(shape=(47959, 75, 50), dtype=float32)\n  • mask=tf.Tensor(shape=(47959, 75), dtype=bool)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2cc7a5b426a5>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# a dense layer as suggested by neuralNer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mcrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCRF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tags\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# CRF layer, n_tags+1(PAD)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmsprop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_contrib/layers/crf.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, X, mask)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'viterbi'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mtest_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviterbi_decoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mtest_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_marginal_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_contrib/layers/crf.py\u001b[0m in \u001b[0;36mviterbi_decoding\u001b[0;34m(self, X, mask)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mviterbi_decoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0minput_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_boundary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             input_energy = self.add_boundary_energy(\n",
            "\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling CRF.call().\n\n\u001b[1mmodule 'keras.backend' has no attribute 'dot'\u001b[0m\n\nArguments received by CRF.call():\n  • X=tf.Tensor(shape=(47959, 75, 50), dtype=float32)\n  • mask=tf.Tensor(shape=(47959, 75), dtype=bool)"
          ]
        }
      ],
      "source": [
        "from keras.models import Model\n",
        "from keras import Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "# from keras_contrib.layers import CRF\n",
        "\n",
        "import tensorflow as tf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "\n",
        "import warnings\n",
        "\n",
        "from keras import backend as K\n",
        "from keras import activations\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras import constraints\n",
        "from keras.layers import Layer\n",
        "from keras.layers import InputSpec\n",
        "import tensorflow as tf\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_marginal_accuracy\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy\n",
        "from keras_contrib.utils.test_utils import to_tuple\n",
        "\n",
        "\n",
        "class CRF(Layer):\n",
        "    \"\"\"An implementation of linear chain conditional random field (CRF).\n",
        "\n",
        "    An linear chain CRF is defined to maximize the following likelihood function:\n",
        "\n",
        "    $$ L(W, U, b; y_1, ..., y_n) := \\frac{1}{Z}\n",
        "    \\sum_{y_1, ..., y_n} \\exp(-a_1' y_1 - a_n' y_n\n",
        "        - \\sum_{k=1^n}((f(x_k' W + b) y_k) + y_1' U y_2)), $$\n",
        "\n",
        "    where:\n",
        "        $Z$: normalization constant\n",
        "        $x_k, y_k$:  inputs and outputs\n",
        "\n",
        "    This implementation has two modes for optimization:\n",
        "    1. (`join mode`) optimized by maximizing join likelihood,\n",
        "    which is optimal in theory of statistics.\n",
        "       Note that in this case, CRF must be the output/last layer.\n",
        "    2. (`marginal mode`) return marginal probabilities on each time\n",
        "    step and optimized via composition\n",
        "       likelihood (product of marginal likelihood), i.e.,\n",
        "       using `categorical_crossentropy` loss.\n",
        "       Note that in this case, CRF can be either the last layer or an\n",
        "       intermediate layer (though not explored).\n",
        "\n",
        "    For prediction (test phrase), one can choose either Viterbi\n",
        "    best path (class indices) or marginal\n",
        "    probabilities if probabilities are needed.\n",
        "    However, if one chooses *join mode* for training,\n",
        "    Viterbi output is typically better than marginal output,\n",
        "    but the marginal output will still perform\n",
        "    reasonably close, while if *marginal mode* is used for training,\n",
        "    marginal output usually performs\n",
        "    much better. The default behavior and `metrics.crf_accuracy`\n",
        "    is set according to this observation.\n",
        "\n",
        "    In addition, this implementation supports masking and accepts either\n",
        "    onehot or sparse target.\n",
        "\n",
        "    If you open a issue or a pull request about CRF, please\n",
        "    add 'cc @lzfelix' to notify Luiz Felix.\n",
        "\n",
        "\n",
        "    # Examples\n",
        "\n",
        "    ```python\n",
        "        from keras_contrib.layers import CRF\n",
        "        from keras_contrib.losses import crf_loss\n",
        "        from keras_contrib.metrics import crf_viterbi_accuracy\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(3001, 300, mask_zero=True)(X)\n",
        "\n",
        "        # use learn_mode = 'join', test_mode = 'viterbi',\n",
        "        # sparse_target = True (label indice output)\n",
        "        crf = CRF(10, sparse_target=True)\n",
        "        model.add(crf)\n",
        "\n",
        "        # crf_accuracy is default to Viterbi acc if using join-mode (default).\n",
        "        # One can add crf.marginal_acc if interested, but may slow down learning\n",
        "        model.compile('adam', loss=crf_loss, metrics=[crf_viterbi_accuracy])\n",
        "\n",
        "        # y must be label indices (with shape 1 at dim 3) here,\n",
        "        # since `sparse_target=True`\n",
        "        model.fit(x, y)\n",
        "\n",
        "        # prediction give onehot representation of Viterbi best path\n",
        "        y_hat = model.predict(x_test)\n",
        "    ```\n",
        "\n",
        "    The following snippet shows how to load a persisted\n",
        "    model that uses the CRF layer:\n",
        "\n",
        "    ```python\n",
        "        from keras.models import load_model\n",
        "        from keras_contrib.losses import import crf_loss\n",
        "        from keras_contrib.metrics import crf_viterbi_accuracy\n",
        "\n",
        "        custom_objects={'CRF': CRF,\n",
        "                        'crf_loss': crf_loss,\n",
        "                        'crf_viterbi_accuracy': crf_viterbi_accuracy}\n",
        "\n",
        "        loaded_model = load_model('<path_to_model>',\n",
        "                                  custom_objects=custom_objects)\n",
        "    ```\n",
        "\n",
        "    # Arguments\n",
        "        units: Positive integer, dimensionality of the output space.\n",
        "        learn_mode: Either 'join' or 'marginal'.\n",
        "            The former train the model by maximizing join likelihood while the latter\n",
        "            maximize the product of marginal likelihood over all time steps.\n",
        "            One should use `losses.crf_nll` for 'join' mode\n",
        "            and `losses.categorical_crossentropy` or\n",
        "            `losses.sparse_categorical_crossentropy` for\n",
        "            `marginal` mode.  For convenience, simply\n",
        "            use `losses.crf_loss`, which will decide the proper loss as described.\n",
        "        test_mode: Either 'viterbi' or 'marginal'.\n",
        "            The former is recommended and as default when `learn_mode = 'join'` and\n",
        "            gives one-hot representation of the best path at test (prediction) time,\n",
        "            while the latter is recommended and chosen as default\n",
        "            when `learn_mode = 'marginal'`,\n",
        "            which produces marginal probabilities for each time step.\n",
        "            For evaluating metrics, one should\n",
        "            use `metrics.crf_viterbi_accuracy` for 'viterbi' mode and\n",
        "            'metrics.crf_marginal_accuracy' for 'marginal' mode, or\n",
        "            simply use `metrics.crf_accuracy` for\n",
        "            both which automatically decides it as described.\n",
        "            One can also use both for evaluation at training.\n",
        "        sparse_target: Boolean (default False) indicating\n",
        "            if provided labels are one-hot or\n",
        "            indices (with shape 1 at dim 3).\n",
        "        use_boundary: Boolean (default True) indicating if trainable\n",
        "            start-end chain energies\n",
        "            should be added to model.\n",
        "        use_bias: Boolean, whether the layer uses a bias vector.\n",
        "        kernel_initializer: Initializer for the `kernel` weights matrix,\n",
        "            used for the linear transformation of the inputs.\n",
        "            (see [initializers](../initializers.md)).\n",
        "        chain_initializer: Initializer for the `chain_kernel` weights matrix,\n",
        "            used for the CRF chain energy.\n",
        "            (see [initializers](../initializers.md)).\n",
        "        boundary_initializer: Initializer for the `left_boundary`,\n",
        "            'right_boundary' weights vectors,\n",
        "            used for the start/left and end/right boundary energy.\n",
        "            (see [initializers](../initializers.md)).\n",
        "        bias_initializer: Initializer for the bias vector\n",
        "            (see [initializers](../initializers.md)).\n",
        "        activation: Activation function to use\n",
        "            (see [activations](../activations.md)).\n",
        "            If you pass None, no activation is applied\n",
        "            (ie. \"linear\" activation: `a(x) = x`).\n",
        "        kernel_regularizer: Regularizer function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        chain_regularizer: Regularizer function applied to\n",
        "            the `chain_kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        boundary_regularizer: Regularizer function applied to\n",
        "            the 'left_boundary', 'right_boundary' weight vectors\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        bias_regularizer: Regularizer function applied to the bias vector\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        kernel_constraint: Constraint function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        chain_constraint: Constraint function applied to\n",
        "            the `chain_kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        boundary_constraint: Constraint function applied to\n",
        "            the `left_boundary`, `right_boundary` weights vectors\n",
        "            (see [constraints](../constraints.md)).\n",
        "        bias_constraint: Constraint function applied to the bias vector\n",
        "            (see [constraints](../constraints.md)).\n",
        "        input_dim: dimensionality of the input (integer).\n",
        "            This argument (or alternatively, the keyword argument `input_shape`)\n",
        "            is required when using this layer as the first layer in a model.\n",
        "        unroll: Boolean (default False). If True, the network will be\n",
        "            unrolled, else a symbolic loop will be used.\n",
        "            Unrolling can speed-up a RNN, although it tends\n",
        "            to be more memory-intensive.\n",
        "            Unrolling is only suitable for short sequences.\n",
        "\n",
        "    # Input shape\n",
        "        3D tensor with shape `(nb_samples, timesteps, input_dim)`.\n",
        "\n",
        "    # Output shape\n",
        "        3D tensor with shape `(nb_samples, timesteps, units)`.\n",
        "\n",
        "    # Masking\n",
        "        This layer supports masking for input data with a variable number\n",
        "        of timesteps. To introduce masks to your data,\n",
        "        use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n",
        "        set to `True`.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, units,\n",
        "                 learn_mode='join',\n",
        "                 test_mode=None,\n",
        "                 sparse_target=False,\n",
        "                 use_boundary=True,\n",
        "                 use_bias=True,\n",
        "                 activation='linear',\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 chain_initializer='orthogonal',\n",
        "                 bias_initializer='zeros',\n",
        "                 boundary_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 chain_regularizer=None,\n",
        "                 boundary_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 chain_constraint=None,\n",
        "                 boundary_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 input_dim=None,\n",
        "                 unroll=False,\n",
        "                 **kwargs):\n",
        "        super(CRF, self).__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.units = units\n",
        "        self.learn_mode = learn_mode\n",
        "        assert self.learn_mode in ['join', 'marginal']\n",
        "        self.test_mode = test_mode\n",
        "        if self.test_mode is None:\n",
        "            self.test_mode = 'viterbi' if self.learn_mode == 'join' else 'marginal'\n",
        "        else:\n",
        "            assert self.test_mode in ['viterbi', 'marginal']\n",
        "        self.sparse_target = sparse_target\n",
        "        self.use_boundary = use_boundary\n",
        "        self.use_bias = use_bias\n",
        "\n",
        "        self.activation = activations.get(activation)\n",
        "\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.chain_initializer = initializers.get(chain_initializer)\n",
        "        self.boundary_initializer = initializers.get(boundary_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.chain_regularizer = regularizers.get(chain_regularizer)\n",
        "        self.boundary_regularizer = regularizers.get(boundary_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.chain_constraint = constraints.get(chain_constraint)\n",
        "        self.boundary_constraint = constraints.get(boundary_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "        self.unroll = unroll\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_shape = to_tuple(input_shape)\n",
        "        self.input_spec = [InputSpec(shape=input_shape)]\n",
        "        self.input_dim = input_shape[-1]\n",
        "\n",
        "        self.kernel = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                      name='kernel',\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        self.chain_kernel = self.add_weight(shape=(self.units, self.units),\n",
        "                                            name='chain_kernel',\n",
        "                                            initializer=self.chain_initializer,\n",
        "                                            regularizer=self.chain_regularizer,\n",
        "                                            constraint=self.chain_constraint)\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.units,),\n",
        "                                        name='bias',\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = 0\n",
        "\n",
        "        if self.use_boundary:\n",
        "            self.left_boundary = self.add_weight(shape=(self.units,),\n",
        "                                                 name='left_boundary',\n",
        "                                                 initializer=self.boundary_initializer,\n",
        "                                                 regularizer=self.boundary_regularizer,\n",
        "                                                 constraint=self.boundary_constraint)\n",
        "            self.right_boundary = self.add_weight(shape=(self.units,),\n",
        "                                                  name='right_boundary',\n",
        "                                                  initializer=self.boundary_initializer,\n",
        "                                                  regularizer=self.boundary_regularizer,\n",
        "                                                  constraint=self.boundary_constraint)\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, X, mask=None):\n",
        "        if mask is not None:\n",
        "            assert tf.rank(mask) == 2, 'Input mask to CRF must have dim 2 if not None'\n",
        "\n",
        "        if self.test_mode == 'viterbi':\n",
        "            test_output = self.viterbi_decoding(X, mask)\n",
        "        else:\n",
        "            test_output = self.get_marginal_prob(X, mask)\n",
        "\n",
        "        self.uses_learning_phase = True\n",
        "        if self.learn_mode == 'join':\n",
        "            train_output = K.zeros_like(K.dot(X, self.kernel))\n",
        "            out = K.in_train_phase(train_output, test_output)\n",
        "        else:\n",
        "            if self.test_mode == 'viterbi':\n",
        "                train_output = self.get_marginal_prob(X, mask)\n",
        "                out = K.in_train_phase(train_output, test_output)\n",
        "            else:\n",
        "                out = test_output\n",
        "        return out\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:2] + (self.units,)\n",
        "\n",
        "    def compute_mask(self, input, mask=None):\n",
        "        if mask is not None and self.learn_mode == 'join':\n",
        "            return tf.reduce_any(mask, axis=1)\n",
        "        return mask\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'units': self.units,\n",
        "            'learn_mode': self.learn_mode,\n",
        "            'test_mode': self.test_mode,\n",
        "            'use_boundary': self.use_boundary,\n",
        "            'use_bias': self.use_bias,\n",
        "            'sparse_target': self.sparse_target,\n",
        "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
        "            'chain_initializer': initializers.serialize(self.chain_initializer),\n",
        "            'boundary_initializer': initializers.serialize(\n",
        "                self.boundary_initializer),\n",
        "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "            'activation': activations.serialize(self.activation),\n",
        "            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
        "            'chain_regularizer': regularizers.serialize(self.chain_regularizer),\n",
        "            'boundary_regularizer': regularizers.serialize(\n",
        "                self.boundary_regularizer),\n",
        "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "            'chain_constraint': constraints.serialize(self.chain_constraint),\n",
        "            'boundary_constraint': constraints.serialize(self.boundary_constraint),\n",
        "            'bias_constraint': constraints.serialize(self.bias_constraint),\n",
        "            'input_dim': self.input_dim,\n",
        "            'unroll': self.unroll}\n",
        "        base_config = super(CRF, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    @property\n",
        "    def loss_function(self):\n",
        "        warnings.warn('CRF.loss_function is deprecated '\n",
        "                      'and it might be removed in the future. Please '\n",
        "                      'use losses.crf_loss instead.')\n",
        "        return crf_loss\n",
        "\n",
        "    @property\n",
        "    def accuracy(self):\n",
        "        warnings.warn('CRF.accuracy is deprecated and it '\n",
        "                      'might be removed in the future. Please '\n",
        "                      'use metrics.crf_accuracy')\n",
        "        if self.test_mode == 'viterbi':\n",
        "            return crf_viterbi_accuracy\n",
        "        else:\n",
        "            return crf_marginal_accuracy\n",
        "\n",
        "    @property\n",
        "    def viterbi_acc(self):\n",
        "        warnings.warn('CRF.viterbi_acc is deprecated and it might '\n",
        "                      'be removed in the future. Please '\n",
        "                      'use metrics.viterbi_acc instead.')\n",
        "        return crf_viterbi_accuracy\n",
        "\n",
        "    @property\n",
        "    def marginal_acc(self):\n",
        "        warnings.warn('CRF.moarginal_acc is deprecated and it '\n",
        "                      'might be removed in the future. Please '\n",
        "                      'use metrics.marginal_acc instead.')\n",
        "        return crf_marginal_accuracy\n",
        "\n",
        "    @staticmethod\n",
        "    def softmaxNd(x, axis=-1):\n",
        "        m = K.max(x, axis=axis, keepdims=True)\n",
        "        exp_x = K.exp(x - m)\n",
        "        prob_x = exp_x / K.sum(exp_x, axis=axis, keepdims=True)\n",
        "        return prob_x\n",
        "\n",
        "    @staticmethod\n",
        "    def shift_left(x, offset=1):\n",
        "        assert offset > 0\n",
        "        return K.concatenate([x[:, offset:], K.zeros_like(x[:, :offset])], axis=1)\n",
        "\n",
        "    @staticmethod\n",
        "    def shift_right(x, offset=1):\n",
        "        assert offset > 0\n",
        "        return K.concatenate([K.zeros_like(x[:, :offset]), x[:, :-offset]], axis=1)\n",
        "\n",
        "    def add_boundary_energy(self, energy, mask, start, end):\n",
        "        start = tf.expand_dims(tf.expand_dims(start, 0), 0)\n",
        "        end = tf.expand_dims(tf.expand_dims(end, 0), 0)\n",
        "        if mask is None:\n",
        "            energy = K.concatenate([energy[:, :1, :] + start, energy[:, 1:, :]],\n",
        "                                   axis=1)\n",
        "            energy = K.concatenate([energy[:, :-1, :], energy[:, -1:, :] + end],\n",
        "                                   axis=1)\n",
        "        else:\n",
        "            mask = tf.expand_dims(tf.cast(mask, K.floatx()))\n",
        "            start_mask = tf.cast(K.greater(mask, self.shift_right(mask)), K.floatx())\n",
        "            end_mask = tf.cast(K.greater(self.shift_left(mask), mask), K.floatx())\n",
        "            energy = energy + start_mask * start\n",
        "            energy = energy + end_mask * end\n",
        "        return energy\n",
        "\n",
        "    def get_log_normalization_constant(self, input_energy, mask, **kwargs):\n",
        "        \"\"\"Compute logarithm of the normalization constant Z, where\n",
        "        Z = sum exp(-E) -> logZ = log sum exp(-E) =: -nlogZ\n",
        "        \"\"\"\n",
        "        # should have logZ[:, i] == logZ[:, j] for any i, j\n",
        "        logZ = self.recursion(input_energy, mask, return_sequences=False, **kwargs)\n",
        "        return logZ[:, 0]\n",
        "\n",
        "    def get_energy(self, y_true, input_energy, mask):\n",
        "        \"\"\"Energy = a1' y1 + u1' y1 + y1' U y2 + u2' y2 + y2' U y3 + u3' y3 + an' y3\n",
        "        \"\"\"\n",
        "        input_energy = K.sum(input_energy * y_true, 2)  # (B, T)\n",
        "        # (B, T-1)\n",
        "        chain_energy = K.sum(K.dot(y_true[:, :-1, :],\n",
        "                                   self.chain_kernel) * y_true[:, 1:, :], 2)\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = tf.cast(mask, K.floatx())\n",
        "            # (B, T-1), mask[:,:-1]*mask[:,1:] makes it work with any padding\n",
        "            chain_mask = mask[:, :-1] * mask[:, 1:]\n",
        "            input_energy = input_energy * mask\n",
        "            chain_energy = chain_energy * chain_mask\n",
        "        total_energy = K.sum(input_energy, -1) + K.sum(chain_energy, -1)  # (B, )\n",
        "\n",
        "        return total_energy\n",
        "\n",
        "    def get_negative_log_likelihood(self, y_true, X, mask):\n",
        "        \"\"\"Compute the loss, i.e., negative log likelihood (normalize by number of time steps)\n",
        "           likelihood = 1/Z * exp(-E) ->  neg_log_like = - log(1/Z * exp(-E)) = logZ + E\n",
        "        \"\"\"\n",
        "        input_energy = self.activation(K.dot(X, self.kernel) + self.bias)\n",
        "        if self.use_boundary:\n",
        "            input_energy = self.add_boundary_energy(input_energy, mask,\n",
        "                                                    self.left_boundary,\n",
        "                                                    self.right_boundary)\n",
        "        energy = self.get_energy(y_true, input_energy, mask)\n",
        "        logZ = self.get_log_normalization_constant(input_energy, mask,\n",
        "                                                   input_length=K.int_shape(X)[1])\n",
        "        nloglik = logZ + energy\n",
        "        if mask is not None:\n",
        "            nloglik = nloglik / K.sum(tf.cast(mask, K.floatx()), 1)\n",
        "        else:\n",
        "            nloglik = nloglik / tf.cast(K.shape(X)[1], K.floatx())\n",
        "        return nloglik\n",
        "\n",
        "    def step(self, input_energy_t, states, return_logZ=True):\n",
        "        # not in the following  `prev_target_val` has shape = (B, F)\n",
        "        # where B = batch_size, F = output feature dim\n",
        "        # Note: `i` is of float32, due to the behavior of `K.rnn`\n",
        "        prev_target_val, i, chain_energy = states[:3]\n",
        "        t = tf.cast(i[0, 0], dtype='int32')\n",
        "        if len(states) > 3:\n",
        "            if K.backend() == 'theano':\n",
        "                m = states[3][:, t:(t + 2)]\n",
        "            else:\n",
        "                m = K.slice(states[3], [0, t], [-1, 2])\n",
        "            input_energy_t = input_energy_t * tf.expand_dims(m[:, 0])\n",
        "            # (1, F, F)*(B, 1, 1) -> (B, F, F)\n",
        "            chain_energy = chain_energy * tf.expand_dims(\n",
        "                tf.expand_dims(m[:, 0] * m[:, 1]))\n",
        "        if return_logZ:\n",
        "            # shapes: (1, B, F) + (B, F, 1) -> (B, F, F)\n",
        "            energy = chain_energy + tf.expand_dims(input_energy_t - prev_target_val, 2)\n",
        "            new_target_val = K.logsumexp(-energy, 1)  # shapes: (B, F)\n",
        "            return new_target_val, [new_target_val, i + 1]\n",
        "        else:\n",
        "            energy = chain_energy + tf.expand_dims(input_energy_t + prev_target_val, 2)\n",
        "            min_energy = K.min(energy, 1)\n",
        "            # cast for tf-version `K.rnn\n",
        "            argmin_table = tf.cast(K.argmin(energy, 1), K.floatx())\n",
        "            return argmin_table, [min_energy, i + 1]\n",
        "\n",
        "    def recursion(self, input_energy, mask=None, go_backwards=False,\n",
        "                  return_sequences=True, return_logZ=True, input_length=None):\n",
        "        \"\"\"Forward (alpha) or backward (beta) recursion\n",
        "\n",
        "        If `return_logZ = True`, compute the logZ, the normalization constant:\n",
        "\n",
        "        \\[ Z = \\sum_{y1, y2, y3} exp(-E) # energy\n",
        "          = \\sum_{y1, y2, y3} exp(-(u1' y1 + y1' W y2 + u2' y2 + y2' W y3 + u3' y3))\n",
        "          = sum_{y2, y3} (exp(-(u2' y2 + y2' W y3 + u3' y3))\n",
        "          sum_{y1} exp(-(u1' y1' + y1' W y2))) \\]\n",
        "\n",
        "        Denote:\n",
        "            \\[ S(y2) := sum_{y1} exp(-(u1' y1 + y1' W y2)), \\]\n",
        "            \\[ Z = sum_{y2, y3} exp(log S(y2) - (u2' y2 + y2' W y3 + u3' y3)) \\]\n",
        "            \\[ logS(y2) = log S(y2) = log_sum_exp(-(u1' y1' + y1' W y2)) \\]\n",
        "        Note that:\n",
        "              yi's are one-hot vectors\n",
        "              u1, u3: boundary energies have been merged\n",
        "\n",
        "        If `return_logZ = False`, compute the Viterbi's best path lookup table.\n",
        "        \"\"\"\n",
        "        chain_energy = self.chain_kernel\n",
        "        # shape=(1, F, F): F=num of output features. 1st F is for t-1, 2nd F for t\n",
        "        chain_energy = tf.expand_dims(chain_energy, 0)\n",
        "        # shape=(B, F), dtype=float32\n",
        "        prev_target_val = K.zeros_like(input_energy[:, 0, :])\n",
        "\n",
        "        if go_backwards:\n",
        "            input_energy = K.reverse(input_energy, 1)\n",
        "            if mask is not None:\n",
        "                mask = K.reverse(mask, 1)\n",
        "\n",
        "        initial_states = [prev_target_val, K.zeros_like(prev_target_val[:, :1])]\n",
        "        constants = [chain_energy]\n",
        "\n",
        "        if mask is not None:\n",
        "            mask2 = tf.cast(K.concatenate([mask, K.zeros_like(mask[:, :1])], axis=1),\n",
        "                           K.floatx())\n",
        "            constants.append(mask2)\n",
        "\n",
        "        def _step(input_energy_i, states):\n",
        "            return self.step(input_energy_i, states, return_logZ)\n",
        "\n",
        "        target_val_last, target_val_seq, _ = K.rnn(_step, input_energy,\n",
        "                                                   initial_states,\n",
        "                                                   constants=constants,\n",
        "                                                   input_length=input_length,\n",
        "                                                   unroll=self.unroll)\n",
        "\n",
        "        if return_sequences:\n",
        "            if go_backwards:\n",
        "                target_val_seq = K.reverse(target_val_seq, 1)\n",
        "            return target_val_seq\n",
        "        else:\n",
        "            return target_val_last\n",
        "\n",
        "    def forward_recursion(self, input_energy, **kwargs):\n",
        "        return self.recursion(input_energy, **kwargs)\n",
        "\n",
        "    def backward_recursion(self, input_energy, **kwargs):\n",
        "        return self.recursion(input_energy, go_backwards=True, **kwargs)\n",
        "\n",
        "    def get_marginal_prob(self, X, mask=None):\n",
        "        input_energy = self.activation(K.dot(X, self.kernel) + self.bias)\n",
        "        if self.use_boundary:\n",
        "            input_energy = self.add_boundary_energy(input_energy, mask,\n",
        "                                                    self.left_boundary,\n",
        "                                                    self.right_boundary)\n",
        "        input_length = K.int_shape(X)[1]\n",
        "        alpha = self.forward_recursion(input_energy, mask=mask,\n",
        "                                       input_length=input_length)\n",
        "        beta = self.backward_recursion(input_energy, mask=mask,\n",
        "                                       input_length=input_length)\n",
        "        if mask is not None:\n",
        "            input_energy = input_energy * tf.expand_dims(tf.cast(mask, K.floatx()))\n",
        "        margin = -(self.shift_right(alpha) + input_energy + self.shift_left(beta))\n",
        "        return self.softmaxNd(margin)\n",
        "\n",
        "    def viterbi_decoding(self, X, mask=None):\n",
        "        input_energy = self.activation(tf.matmul(X, self.kernel) + self.bias)\n",
        "        if self.use_boundary:\n",
        "            input_energy = self.add_boundary_energy(\n",
        "                input_energy, mask, self.left_boundary, self.right_boundary)\n",
        "\n",
        "        argmin_tables = self.recursion(input_energy, mask, return_logZ=False)\n",
        "        argmin_tables = tf.cast(argmin_tables, 'int32')\n",
        "\n",
        "        # backward to find best path, `initial_best_idx` can be any,\n",
        "        # as all elements in the last argmin_table are the same\n",
        "        argmin_tables = K.reverse(argmin_tables, 1)\n",
        "        # matrix instead of vector is required by tf `K.rnn`\n",
        "        initial_best_idx = [tf.expand_dims(argmin_tables[:, 0, 0])]\n",
        "        if K.backend() == 'theano':\n",
        "            from theano import tensor as T\n",
        "            initial_best_idx = [T.unbroadcast(initial_best_idx[0], 1)]\n",
        "\n",
        "        def gather_each_row(params, indices):\n",
        "            n = K.shape(indices)[0]\n",
        "            if K.backend() == 'theano':\n",
        "                from theano import tensor as T\n",
        "                return params[T.arange(n), indices]\n",
        "            elif K.backend() == 'tensorflow':\n",
        "                import tensorflow as tf\n",
        "                indices = K.transpose(K.stack([tf.range(n), indices]))\n",
        "                return tf.gather_nd(params, indices)\n",
        "            else:\n",
        "                raise NotImplementedError\n",
        "\n",
        "        def find_path(argmin_table, best_idx):\n",
        "            next_best_idx = gather_each_row(argmin_table, best_idx[0][:, 0])\n",
        "            next_best_idx = tf.expand_dims(next_best_idx)\n",
        "            if K.backend() == 'theano':\n",
        "                from theano import tensor as T\n",
        "                next_best_idx = T.unbroadcast(next_best_idx, 1)\n",
        "            return next_best_idx, [next_best_idx]\n",
        "\n",
        "        _, best_paths, _ = K.rnn(find_path, argmin_tables, initial_best_idx,\n",
        "                                 input_length=K.int_shape(X)[1], unroll=self.unroll)\n",
        "        best_paths = K.reverse(best_paths, 1)\n",
        "        best_paths = K.squeeze(best_paths, 2)\n",
        "\n",
        "        return K.one_hot(best_paths, self.units)\n"
      ],
      "metadata": {
        "id": "ee3nHeba28XB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.12.0 # Install version that was used\n",
        "!pip install keras==2.12.0 # Install version that was used\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import  Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, TimeDistributed, Dense\n",
        "from keras_contrib.layers import CRF\n",
        "\n",
        "# Assuming MAX_LEN, n_words, EMBEDDING, and n_tags are defined\n",
        "\n",
        "# Định nghĩa mô hình\n",
        "# đầu vào\n",
        "input = Input(shape=(MAX_LEN,))\n",
        "# lớp embedding\n",
        "model = Embedding(input_dim=n_words+2, output_dim=EMBEDDING,\n",
        "                  input_length=MAX_LEN, mask_zero=True)(input)  # 20-dim embedding\n",
        "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
        "                           recurrent_dropout=0.1))(model)  # variational biLSTM\n",
        "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
        "crf = CRF(n_tags+1)  # CRF layer, n_tags+1(PAD)\n",
        "\n",
        "# Wrap the CRF layer call within a Lambda layer to handle the KerasTensor\n",
        "out = crf(model)  # output\n",
        "\n",
        "model = Model(input, out)\n",
        "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MrNPsnDm7A1E",
        "outputId": "2b6b1bb6-4b47-4510-e4c6-6419ee0b228c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.11.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.33)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12.0)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12.0)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.44.0)\n",
            "Requirement already satisfied: jaxlib<=0.4.33,>=0.4.33 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.33)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.34-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.31-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.30-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.13.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jaxlib-0.4.30-cp310-cp310-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, numpy, keras, gast, jaxlib, google-auth-oauthlib, tensorboard, jax, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.16.0\n",
            "    Uninstalling wrapt-1.16.0:\n",
            "      Successfully uninstalled wrapt-1.16.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.33\n",
            "    Uninstalling jaxlib-0.4.33:\n",
            "      Successfully uninstalled jaxlib-0.4.33\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.33\n",
            "    Uninstalling jax-0.4.33:\n",
            "      Successfully uninstalled jax-0.4.33\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.16 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.15 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.22.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.12.0 which is incompatible.\n",
            "xarray 2024.9.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 numpy-1.23.5 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "48175b1a194f4b769429bcc0b949a4bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras==2.12.0 in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-7chw2mxn\n",
            "  Running command git clone --filter=blob:none --quiet https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-7chw2mxn\n",
            "  warning: redirecting to https://github.com/keras-team/keras-contrib.git/\n",
            "  Resolved https://www.github.com/keras-team/keras-contrib.git to commit 3fc5ef709e061416f4bc8a92ca3750c824b5d2b0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_contrib==2.0.8) (2.12.0)\n",
            "Building wheels for collected packages: keras_contrib\n",
            "  Building wheel for keras_contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101059 sha256=afaaa3278c51bd77e4a018964643df55ff4b5ae0f7382323ff36f49a5f0e6113\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-eh_2urab/wheels/74/d5/f7/0245af7ac33d5b0c2e095688649916e4bf9a8d6b3362a849f5\n",
            "Successfully built keras_contrib\n",
            "Installing collected packages: keras_contrib\n",
            "Successfully installed keras_contrib-2.0.8\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'MAX_LEN' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8014934cfca4>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Định nghĩa mô hình\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# đầu vào\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m# lớp embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m model = Embedding(input_dim=n_words+2, output_dim=EMBEDDING,\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MAX_LEN' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BHyziBXcrcC"
      },
      "source": [
        "## Huấn luyện và đánh giá mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "viCzUCm-crcC",
        "outputId": "ce2dffad-4cdd-4b7f-ad0f-8cc0383b7b30"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'fit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0148fba622f3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# huấn luyện mô hình\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(X_tr, np.array(y_tr), batch_size=BATCH_SIZE, verbose=1, \n\u001b[0m\u001b[1;32m      3\u001b[0m                     epochs=EPOCHS, validation_split=0.1)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_enable_numpy_behavior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m       \"\"\")\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'fit'"
          ]
        }
      ],
      "source": [
        "# huấn luyện mô hình\n",
        "history = model.fit(X_tr, np.array(y_tr), batch_size=BATCH_SIZE, verbose=1,\n",
        "                    epochs=EPOCHS, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUkd1VnwcrcD"
      },
      "outputs": [],
      "source": [
        "# Đánh giá mô hình trên tập test\n",
        "pred_cat = ### YOUR CODE HERE ###\n",
        "pred = ### YOUR CODE HERE ###\n",
        "y_te_true = ### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdgkivfdcrcD"
      },
      "outputs": [],
      "source": [
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "\n",
        "# Convert the index to tag\n",
        "pred_tag = [[idx2tag[i] for i in row] for row in pred]\n",
        "y_te_true_tag = [[idx2tag[i] for i in row] for row in y_te_true]\n",
        "\n",
        "report = flat_classification_report(y_pred=pred_tag, y_true=y_te_true_tag)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVFA-BdzcrcD"
      },
      "source": [
        "Đánh giá một vài mẫu trên tập test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5yRP_L1crcE"
      },
      "outputs": [],
      "source": [
        "# chọn 1 câu ngẫu nhiên\n",
        "i = ### YOUR CODE HERE ###\n",
        "# dự đoán kết quả\n",
        "p = ### YOUR CODE HERE ###\n",
        "p = ### YOUR CODE HERE ###\n",
        "true = np.argmax(y_te[i], -1)\n",
        "\n",
        "print(\"Sample number {} of {} (Test Set)\".format(i, X_te.shape[0]))\n",
        "# Visualization\n",
        "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
        "print(30 * \"=\")\n",
        "for w, t, pred in zip(X_te[i], true, p[0]):\n",
        "    if w != 0:\n",
        "        print(\"{:15}: {:5} {}\".format(words[w-2], idx2tag[t], idx2tag[pred]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIGUho4pcrcE"
      },
      "source": [
        "# lưu mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ga5ocW3FcrcE"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Saving Vocab\n",
        "with open('models/word_to_index.pickle', 'wb') as handle:\n",
        "    pickle.dump(word2idx, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Saving Vocab\n",
        "with open('models/tag_to_index.pickle', 'wb') as handle:\n",
        "    pickle.dump(tag2idx, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Lưu mô hình\n",
        "model.save_weights('models/lstm_crf_weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4v-3AB_crcE"
      },
      "source": [
        "## Load mô hình và dự đoán kết quả một số câu do người dùng tự gõ vào\n",
        "Ví dụ:\n",
        "- Obama was the president of USA.\n",
        "- The 1906 San Francisco earthquake was the biggest earthquake that has ever hit San Francisco on April 18, 1906\n",
        "- Next Monday is Christmas!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iPBvY8McrcE"
      },
      "outputs": [],
      "source": [
        "# load lại mô hình\n",
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpsawED-crcE"
      },
      "outputs": [],
      "source": [
        "# dự đoán kết quả cho 3 câu trên\n",
        "### YOUR CODE HERE ###"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}